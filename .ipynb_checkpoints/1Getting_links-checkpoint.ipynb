{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Creates links.txt file, which contains links to all the poems"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "links_concrete = {\n",
    "    \"contemporary\": \"https://www.poema.art.pl/kontener/24-polska-wspolczesna\",\n",
    "    \"classics\": \"https://www.poema.art.pl/kontener/1-poezja-polska\",\n",
    "    }\n",
    "\n",
    "BASE_ADDR = \"https://www.poema.art.pl\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "links_dir = \"https://www.poema.art.pl/kontener/35-debiuty-poezja\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "import requests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fetch_conteners_list(link, with_titles=False):\n",
    "    bs = BeautifulSoup(requests.get(link).content)\n",
    "    links = []\n",
    "    descs = []\n",
    "    content = bs.find(\"div\", \"content\")\n",
    "    try:\n",
    "        for c in content.findAll(\"p\", \"title\"):\n",
    "            x = c.find(\"a\")\n",
    "            links.append(x.attrs[\"href\"])\n",
    "            descs.append(x.string)\n",
    "        links = [BASE_ADDR + l for l in links]\n",
    "    except:\n",
    "        pass\n",
    "    \n",
    "    if with_titles:\n",
    "        return list(zip(links, descs))\n",
    "    else:\n",
    "        links\n",
    "\n",
    "def flatten(l):\n",
    "    return [x for ll in l for x in ll]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "from time import sleep"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jack/anaconda3/lib/python3.5/site-packages/bs4/__init__.py:181: UserWarning: No parser was explicitly specified, so I'm using the best available HTML parser for this system (\"lxml\"). This usually isn't a problem, but if you run this code on another system, or in a different virtual environment, it may use a different parser and behave differently.\n",
      "\n",
      "The code that caused this warning is on line 184 of the file /home/jack/anaconda3/lib/python3.5/runpy.py. To get rid of this warning, change code that looks like this:\n",
      "\n",
      " BeautifulSoup([your markup])\n",
      "\n",
      "to this:\n",
      "\n",
      " BeautifulSoup([your markup], \"lxml\")\n",
      "\n",
      "  markup_type=markup_type))\n",
      "\n",
      "  0%|          | 0/33 [00:00<?, ?it/s]\u001b[A\n",
      "100%|██████████| 33/33 [01:22<00:00,  1.87s/it]\n"
     ]
    }
   ],
   "source": [
    "links = []\n",
    "for l in tqdm(fetch_conteners_list(links_dir)):\n",
    "    links.append(fetch_conteners_list(l))\n",
    "    sleep(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jack/anaconda3/lib/python3.5/site-packages/bs4/__init__.py:181: UserWarning: No parser was explicitly specified, so I'm using the best available HTML parser for this system (\"lxml\"). This usually isn't a problem, but if you run this code on another system, or in a different virtual environment, it may use a different parser and behave differently.\n",
      "\n",
      "The code that caused this warning is on line 184 of the file /home/jack/anaconda3/lib/python3.5/runpy.py. To get rid of this warning, change code that looks like this:\n",
      "\n",
      " BeautifulSoup([your markup])\n",
      "\n",
      "to this:\n",
      "\n",
      " BeautifulSoup([your markup], \"lxml\")\n",
      "\n",
      "  markup_type=markup_type))\n"
     ]
    }
   ],
   "source": [
    "for k, v in links_concrete.items():\n",
    "    links.append(fetch_conteners_list(v))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "links = flatten(links)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  0%|          | 0/10221 [00:00<?, ?it/s]\u001b[A/home/jack/anaconda3/lib/python3.5/site-packages/bs4/__init__.py:181: UserWarning: No parser was explicitly specified, so I'm using the best available HTML parser for this system (\"lxml\"). This usually isn't a problem, but if you run this code on another system, or in a different virtual environment, it may use a different parser and behave differently.\n",
      "\n",
      "The code that caused this warning is on line 184 of the file /home/jack/anaconda3/lib/python3.5/runpy.py. To get rid of this warning, change code that looks like this:\n",
      "\n",
      " BeautifulSoup([your markup])\n",
      "\n",
      "to this:\n",
      "\n",
      " BeautifulSoup([your markup], \"lxml\")\n",
      "\n",
      "  markup_type=markup_type))\n",
      "\n",
      "  0%|          | 1/10221 [00:00<1:43:20,  1.65it/s]\u001b[A\n",
      "  0%|          | 2/10221 [00:01<1:39:27,  1.71it/s]\u001b[A\n",
      "  0%|          | 3/10221 [00:01<1:38:48,  1.72it/s]\u001b[A\n",
      "  0%|          | 4/10221 [00:02<1:39:31,  1.71it/s]\u001b[A\n",
      "  0%|          | 5/10221 [00:02<1:43:09,  1.65it/s]\u001b[A\n",
      "  0%|          | 6/10221 [00:03<1:37:31,  1.75it/s]\u001b[A\n",
      "  0%|          | 7/10221 [00:03<1:34:56,  1.79it/s]\u001b[A\n",
      "  0%|          | 8/10221 [00:04<1:35:47,  1.78it/s]\u001b[A\n",
      "  0%|          | 9/10221 [00:05<1:36:59,  1.75it/s]\u001b[A\n",
      "  0%|          | 10/10221 [00:05<1:41:43,  1.67it/s]\u001b[A\n",
      "  0%|          | 11/10221 [00:06<1:41:16,  1.68it/s]\u001b[A\n",
      "  0%|          | 12/10221 [00:06<1:37:37,  1.74it/s]\u001b[A\n",
      "  0%|          | 13/10221 [00:07<1:41:34,  1.67it/s]\u001b[A\n",
      "100%|██████████| 10221/10221 [2:15:07<00:00, 11.87s/it]\n"
     ]
    }
   ],
   "source": [
    "all_poems_links = []\n",
    "broken = []\n",
    "for l in tqdm(links):\n",
    "    try:\n",
    "        all_poems_links.append(fetch_conteners_list(l, with_titles=True))\n",
    "    except:\n",
    "        broken.append(l)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_poems_links = flatten(all_poems_links)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "100535"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(all_poems_links)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"links.txt\", \"w\") as f:\n",
    "    for k, v in all_poems_links:\n",
    "        try:\n",
    "            f.write(k + \"\\t\" + v + \"\\n\")\n",
    "        except:\n",
    "            pass"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
